{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"include_colab_link":true},"accelerator":"GPU","gpuClass":"standard","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":202005,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":172347,"modelId":194689},{"sourceId":202096,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":172420,"modelId":194761}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b202ec9d-7d3c-44c4-baf6-adfddc6b4237","cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Page0526/Pytorch-crash-course/blob/main/deep-neural-networks/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"id":"b9551c52-6c5e-4b63-a375-8254297bb209","cell_type":"markdown","source":"Ý tưởng của VAE là encode input dưới latent space xong đó decode ra output (reconstructed image) gần giống với input. Ở đấy input sẽ được encoder as a distribution).\nFollow: https://medium.com/@outerrencedl/variational-autoencoder-and-a-bit-kl-divergence-with-pytorch-ce04fd55d0d7","metadata":{"id":"Ld5DLAPGbSGs"}},{"id":"2da611ac-a8b8-407d-8c79-9b6023bdb055","cell_type":"markdown","source":"## Preliminaries","metadata":{"id":"bZ5oWa89GOy7"}},{"id":"0d25ba46-f5ee-4352-a965-ce8217c2288e","cell_type":"code","source":"!pip install -q lightning wandb torchvision torchinfo torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T01:48:17.116989Z","iopub.execute_input":"2024-12-18T01:48:17.117524Z","iopub.status.idle":"2024-12-18T01:48:28.985599Z","shell.execute_reply.started":"2024-12-18T01:48:17.117460Z","shell.execute_reply":"2024-12-18T01:48:28.984330Z"}},"outputs":[],"execution_count":1},{"id":"d8eaae9a-f1ea-4f5c-922d-a5a1ec07d4ec","cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nfrom torchsummary import summary\n\nimport torchvision\nfrom torchvision import transforms\n\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport wandb \nimport pytorch_lightning as pl\nfrom pytz import timezone\nfrom datetime import datetime\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom PIL import Image\nfrom torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\nfrom torchmetrics import MaxMetric, MeanMetric\nfrom typing import Any, Dict, Tuple, List\nfrom torchmetrics.classification.accuracy import Accuracy\nfrom torchattacks import FGSM","metadata":{"id":"1525c069","execution":{"iopub.status.busy":"2024-12-18T01:51:27.983385Z","iopub.execute_input":"2024-12-18T01:51:27.983971Z","iopub.status.idle":"2024-12-18T01:51:27.989673Z","shell.execute_reply.started":"2024-12-18T01:51:27.983936Z","shell.execute_reply":"2024-12-18T01:51:27.988777Z"},"trusted":true},"outputs":[],"execution_count":18},{"id":"95a8a34a-4048-4050-9907-ac5f4a539825","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api_key = user_secrets.get_secret(\"wandb_api_key\")\nwandb.login(key=wandb_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T01:49:39.707737Z","iopub.execute_input":"2024-12-18T01:49:39.708338Z","iopub.status.idle":"2024-12-18T01:49:41.127987Z","shell.execute_reply.started":"2024-12-18T01:49:39.708303Z","shell.execute_reply":"2024-12-18T01:49:41.127173Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"id":"0af65ff7-c0e1-4f15-9bc5-8162e12ec01a","cell_type":"markdown","source":"## Gaussian distribution\n$f(x)=\\frac1 {\\sigma \\sqrt{2\\pi}}e^{-\\frac1 2 (\\frac{x-\\mu}{\\mu})^2}$","metadata":{}},{"id":"0ed52520-e736-441d-8850-81575e802dcf","cell_type":"code","source":"# sampling normal distribution\ndef normal_sample(x, mean, var):\n    return (1/(np.sqrt(2* np.pi * var))) * (np.exp(-0.5 * (x-mean)**2 / var))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7c68c623-c8d3-40c5-8826-170c9d2380c8","cell_type":"code","source":"mean = [0.0,0.0,0.0,-2.0]\nvar = [0.2,1.0,5.0,0.5]\nx_range = np.arange(-5.0, 5.0, 0.05)\ncurves = []\n\n# visualize normal distribution\nfor i in range(len(mean)):\n    crv = [normal_sample(x, mean[i], var[i]) for x in x_range]\n    curves.append(crv)\n    \nplt.figure(figsize=(8,4))\nfor i in range(len(curves)):\n    plt.plot(x_range, curves[i], label=f\"$\\mu$={mean[i]}, $\\sigma^2$={var[i]}\")\n    \nplt.grid(\"on\")\nplt.legend()\nplt.show","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7cc52dd8-8edb-4d5b-ba3d-300e07cab483","cell_type":"markdown","source":"## KL Divergence\n$KL=(\\mathbb{N}(x|\\mu_1,\\sigma_1)||\\mathbb{N}(x|\\mu_2,\\sigma_2))=log\\frac{\\sigma_2}{\\sigma_1}+\\frac{\\sigma_1^2+(\\mu_1-\\mu_2)^2}{2\\sigma_2^2}-\\frac12$","metadata":{}},{"id":"06a5dbb8-0892-46dd-acdd-cd3ab4ef18d4","cell_type":"code","source":"kl_loss = lambda mean1, mean2, var1, var2:(\n        np.log((var2 / var1)**0.5) + (var1 + (mean1-mean2)**2) / (2 * var2) - 0.5)\nprint(\"The KL divergence between curve 0 and curve 1:\")\nprint(f\"{kl_loss(mean[0], mean[1], var[0], var[1]):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2a6cfb24-436b-4b34-a190-260e129da958","cell_type":"markdown","source":"## Point-wise KL divergence\n$KL(p||q)=\\sum^K_{k=1}p_klogp_k-\\sum^K_{k=1}p_klogq_k=\\sum^K_{k=1}p_klog\\frac{p_k}{q_k}$","metadata":{}},{"id":"c053672d-46d5-456b-9791-0f6ecd729976","cell_type":"code","source":"def pt_wise_kl(d_true, d_pred):\n    d_pred, d_true = np.array(d_pred), np.array(d_true)\n    return np.sum(d_true * np.log(d_true / d_pred))\n\nprint(f\"{pt_wise_kl(curves[0], curves[1]):.4f}\")\nprint(f\"{pt_wise_kl(curves[1], curves[0]):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e1d0b8c4-08c9-49c2-afeb-87598afad62f","cell_type":"markdown","source":"## Loading FashionMNIST Dataset","metadata":{"id":"c87956ce"}},{"id":"fbdb7f84-23b8-47a1-b84a-c7f5704e9dae","cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import datasets\n\ntrainset = datasets.MNIST(root=\"data\",\n                                 train=True,\n                                 download=True,\n                                 transform=transforms.Compose([\n                                     transforms.ToTensor(),\n                                 ]),\n                                 target_transform=None \n        )\n\ntestset = datasets.MNIST(root=\"data\",\n                                train=False,\n                                download=True,\n                                transform=transforms.Compose([\n                                    transforms.ToTensor(),\n                                ]),\n                                target_transform=None # you can transform labels as well\n)","metadata":{"id":"pQNST75Kmnzz","outputId":"f83fcc91-8f5f-4b2b-d988-deefd1a79901","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-18T02:57:14.433380Z","iopub.execute_input":"2024-12-18T02:57:14.433779Z","iopub.status.idle":"2024-12-18T02:57:16.711883Z","shell.execute_reply.started":"2024-12-18T02:57:14.433745Z","shell.execute_reply":"2024-12-18T02:57:16.710942Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n  0%|          | 0/9912422 [00:00<?, ?it/s]\u001b[A\n100%|██████████| 9912422/9912422 [00:00<00:00, 54449971.38it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 28881/28881 [00:00<00:00, 1622997.89it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Failed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n100%|██████████| 1648877/1648877 [00:00<00:00, 13932992.05it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 4542/4542 [00:00<00:00, 1989611.36it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":57},{"id":"b5a8025b-2541-4dbc-b48a-2916c7c33cc2","cell_type":"code","source":"# Checking if CUDA is available on current machine\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Deivce: {DEVICE}')\n\nBATCH_SIZE = 64\nEPOCHS = 30\nlr = 2e-3\nHIDDEN_DIM = 2\nlabels = trainset.classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T02:57:16.713344Z","iopub.execute_input":"2024-12-18T02:57:16.713612Z","iopub.status.idle":"2024-12-18T02:57:16.718424Z","shell.execute_reply.started":"2024-12-18T02:57:16.713586Z","shell.execute_reply":"2024-12-18T02:57:16.717569Z"}},"outputs":[{"name":"stdout","text":"Deivce: cuda\n","output_type":"stream"}],"execution_count":58},{"id":"d37ecb4a-8c84-4df8-8f51-6173bd0b4fdf","cell_type":"code","source":"train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=3)\ntest_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T02:57:17.458028Z","iopub.execute_input":"2024-12-18T02:57:17.458389Z","iopub.status.idle":"2024-12-18T02:57:17.463220Z","shell.execute_reply.started":"2024-12-18T02:57:17.458356Z","shell.execute_reply":"2024-12-18T02:57:17.462351Z"}},"outputs":[],"execution_count":59},{"id":"7a872142-e814-4877-92aa-b7128906940c","cell_type":"code","source":"# Visualize data\nfor _, data in enumerate(train_loader):\n  print(\"Batch shape: \",data[0].shape)\n  fig, ax = plt.subplots(1, 4, figsize=(10, 4))\n\n  for i in range(4):\n    # Turn 3D tensor to 2D tensor due to image's single channel\n    ax[i].imshow(data[0][i].squeeze(), cmap='gray')\n    ax[i].axis(\"off\")\n    ax[i].set_title(labels[data[1][i]])\n\n  plt.show()\n  break","metadata":{"id":"kPdozU39mpo0","outputId":"4804e7f4-333c-4b9b-d70a-64117f9ef9d7","colab":{"base_uri":"https://localhost:8080/","height":245},"execution":{"iopub.status.busy":"2024-12-18T02:57:18.518339Z","iopub.execute_input":"2024-12-18T02:57:18.518696Z","iopub.status.idle":"2024-12-18T02:57:19.102392Z","shell.execute_reply.started":"2024-12-18T02:57:18.518663Z","shell.execute_reply":"2024-12-18T02:57:19.101468Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Batch shape:  torch.Size([64, 1, 28, 28])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x400 with 4 Axes>","image/png":"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"},"metadata":{}}],"execution_count":60},{"id":"a0019a20-0ee1-4651-903f-76b08d133e14","cell_type":"markdown","source":"# Classifier","metadata":{}},{"id":"aa677cd3-8158-4ee9-95fe-aecb5974c364","cell_type":"code","source":"class FashionClassifier(nn.Module):\n    def __init__(self, channels:int=1, image_size:int=28):\n        super(FashionClassifier, self).__init__()\n        self.channels = channels\n        self.image_size = image_size\n\n        self.conv1 = nn.Conv2d(self.channels, out_channels=128, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1)\n       \n        self.flatten = nn.Flatten()\n    \n        self.fc1 = nn.Linear(64 * (image_size // 2) * (image_size // 2), 128)\n        self.fc2 = nn.Linear(128, 10)\n\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        \n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        \n        x = self.flatten(x)\n        \n        x = self.dropout1(x)\n        \n        x = F.relu(self.fc1(x))\n        \n        x = self.dropout2(x)\n        \n        x = self.fc2(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:02:02.417864Z","iopub.execute_input":"2024-12-18T04:02:02.418268Z","iopub.status.idle":"2024-12-18T04:02:02.426060Z","shell.execute_reply.started":"2024-12-18T04:02:02.418233Z","shell.execute_reply":"2024-12-18T04:02:02.425150Z"}},"outputs":[],"execution_count":66},{"id":"874695aa-8761-4096-9faa-30c7717fd438","cell_type":"code","source":"fashion_classifier = FashionClassifier().to(DEVICE)\n\nsummary(fashion_classifier, (1, 28, 28))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T11:56:10.170602Z","iopub.execute_input":"2024-12-17T11:56:10.170958Z","iopub.status.idle":"2024-12-17T11:56:10.470678Z","shell.execute_reply.started":"2024-12-17T11:56:10.170926Z","shell.execute_reply":"2024-12-17T11:56:10.469700Z"}},"outputs":[{"name":"stdout","text":"FashionClassifier(\n  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n  (dropout1): Dropout(p=0.25, inplace=False)\n  (dropout2): Dropout(p=0.5, inplace=False)\n)\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1          [-1, 128, 28, 28]           1,280\n            Conv2d-2           [-1, 64, 14, 14]          73,792\n           Flatten-3                [-1, 12544]               0\n           Dropout-4                [-1, 12544]               0\n            Linear-5                  [-1, 128]       1,605,760\n           Dropout-6                  [-1, 128]               0\n            Linear-7                   [-1, 10]           1,290\n================================================================\nTotal params: 1,682,122\nTrainable params: 1,682,122\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 1.05\nParams size (MB): 6.42\nEstimated Total Size (MB): 7.47\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":8},{"id":"0ef5db83-a69c-4754-901e-b942a46001ce","cell_type":"code","source":"class ClassifierModule(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n\n        self.net = FashionClassifier()\n        self.criterion = nn.CrossEntropyLoss()\n        \n        self.train_acc = Accuracy(task=\"multiclass\", num_classes=len(labels))\n        self.val_acc = Accuracy(task=\"multiclass\", num_classes=len(labels))\n        self.test_acc = Accuracy(task=\"multiclass\", num_classes=len(labels))\n\n        self.train_loss = MeanMetric()\n        self.val_loss = MeanMetric()\n        self.test_loss = MeanMetric()\n\n        self.val_acc_best = MaxMetric()\n\n    def forward(self, x): \n        return self.net(x)\n\n    def model_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor]\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n\n        x, y = batch\n        logits = self.forward(x)\n        loss = F.cross_entropy(logits.float(), y)\n        preds = torch.argmax(logits, dim=1)\n\n        return loss, preds, y\n        \n    def on_train_start(self) -> None:\n        \"\"\"Lightning hook that is called when training begins.\"\"\"\n        # by default lightning executes validation step sanity checks before training starts,\n        # so it's worth to make sure validation metrics don't store results from these checks\n        self.val_loss.reset()\n        self.val_acc.reset()\n        self.val_acc_best.reset()\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        loss, preds, targets = self.model_step(batch)\n        \n        self.train_loss(loss)\n        self.train_acc(preds, targets)\n        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"train/acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n        x, y = batch\n        loss, preds, targets = self.model_step(batch)\n\n        self.val_loss(loss)\n        self.val_acc(preds, targets)\n        \n        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/acc\", self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n\n    def on_validation_epoch_end(self) -> None:\n        \"Lightning hook that is called when a validation epoch ends.\"\n        acc = self.val_acc.compute() \n        self.val_acc_best(acc)  \n        self.log(\"val/acc_best\", self.val_acc_best.compute(), sync_dist=True, prog_bar=True)\n\n    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n        x, y = batch\n        loss, preds, targets = self.model_step(batch)\n        \n        self.test_loss(loss)\n        self.test_acc(preds, targets)\n        \n        self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/acc\", self.test_acc, on_step=False, on_epoch=True, prog_bar=True)\n\n\n    def configure_optimizers(self):\n        optimizer=torch.optim.Adam(params=self.parameters(), lr=0.001)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=10)\n      \n        return {\n           \"optimizer\": optimizer,\n           \"lr_scheduler\": {\n               \"scheduler\": scheduler,\n               \"monitor\": \"val/loss\",\n           },\n        }    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:18:33.909083Z","iopub.execute_input":"2024-12-18T04:18:33.909490Z","iopub.status.idle":"2024-12-18T04:18:33.924655Z","shell.execute_reply.started":"2024-12-18T04:18:33.909453Z","shell.execute_reply":"2024-12-18T04:18:33.923580Z"}},"outputs":[],"execution_count":87},{"id":"eb93cb85-9c00-4287-b880-632be86e7d1e","cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n   dirpath=\"checkpoints\",\n   monitor=\"val/loss\",\n   filename=\"classifier-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\",\n   save_top_k=3,\n   mode=\"min\",\n)\n\nearly_stopping = EarlyStopping(monitor=\"val/loss\", patience=3, mode=\"min\", verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:18:34.494533Z","iopub.execute_input":"2024-12-18T04:18:34.494897Z","iopub.status.idle":"2024-12-18T04:18:34.501104Z","shell.execute_reply.started":"2024-12-18T04:18:34.494864Z","shell.execute_reply":"2024-12-18T04:18:34.500286Z"}},"outputs":[],"execution_count":88},{"id":"75bb52f9-bfb1-4416-a3d9-fd7c70141d90","cell_type":"code","source":"current_datetime = datetime.now(timezone(\"UTC\")).strftime(\"%Y-%m-%d_%H-%M-%S\")\nlogger = WandbLogger(project=\"puvae\", name=f\"run-{current_datetime}\", tags= [\"fashion\", \"classifier\"])\n\nclassifier = ClassifierModule()\ntrainer = pl.Trainer(\n    max_epochs=30,\n    logger=logger,\n    callbacks = [checkpoint_callback, early_stopping],\n    accumulate_grad_batches=2,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    devices=\"auto\",\n)\n\ntrainer.fit(classifier, train_dataloaders=train_loader, val_dataloaders=test_loader)\n\nlogger.experiment.save(\"checkpoints/*.ckpt\")\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:18:34.965540Z","iopub.execute_input":"2024-12-18T04:18:34.965888Z","iopub.status.idle":"2024-12-18T04:20:32.742655Z","shell.execute_reply.started":"2024-12-18T04:18:34.965856Z","shell.execute_reply":"2024-12-18T04:20:32.741883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004e6f7848ff4fe3836cb53cd539a08b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 12 files into the W&B run directory, call wandb.save again to sync new files.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='192.192 MB of 340.590 MB uploaded\\r'), FloatProgress(value=0.5642904183337211, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>train/acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>val/acc</td><td>▁▃▆▇▇▇████</td></tr><tr><td>val/acc_best</td><td>▁▃▆▇▇▇████</td></tr><tr><td>val/loss</td><td>█▅▃▁▂▂▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train/acc</td><td>0.9884</td></tr><tr><td>train/loss</td><td>0.03565</td></tr><tr><td>trainer/global_step</td><td>4689</td></tr><tr><td>val/acc</td><td>0.989</td></tr><tr><td>val/acc_best</td><td>0.9897</td></tr><tr><td>val/loss</td><td>0.03607</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">run-2024-12-18_04-12-06</strong> at: <a href='https://wandb.ai/iai-uet-vnu/puvae/runs/11ivt5wx' target=\"_blank\">https://wandb.ai/iai-uet-vnu/puvae/runs/11ivt5wx</a><br/> View project at: <a href='https://wandb.ai/iai-uet-vnu/puvae' target=\"_blank\">https://wandb.ai/iai-uet-vnu/puvae</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 12 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241218_041207-11ivt5wx/logs</code>"},"metadata":{}}],"execution_count":89},{"id":"2cdaf71e-1985-448b-a2a2-fd65b5f7f365","cell_type":"markdown","source":"# VAE Architecture","metadata":{}},{"id":"655e030e-8a1d-4de0-bbaf-8f4b1fd3fcda","cell_type":"code","source":"from abc import abstractmethod\nfrom torch import Tensor\n\nclass BaseVAE(nn.Module):\n\n    def __init__(self) -> None:\n        super().__init__()\n\n    def encode(self, img: Tensor) -> Tuple[Tensor, Tensor]:\n        raise NotImplementedError\n\n    def decode(self, z: Tensor) -> Tensor:\n        raise NotImplementedError\n\n    @torch.no_grad()\n    def sample(self, n_samples: int, device: str = torch.device(\"cpu\")) -> Tensor:\n        \"\"\"_summary_\n        Samples from the latent space and return the corresponding image space map.\n        Args:\n            n_samples (int): Number of samples\n            device (str, optional): Device to run the model. Defaults to torch.device(\"cpu\").\n\n        Returns:\n            Tensor: _description_\n        \"\"\"\n\n        z = torch.randn(n_samples, self.latent_dims[0], self.latent_dims[1],\n                        self.latent_dims[2], device=device)\n        return self.decode(z)\n\n    @abstractmethod\n    def forward(self, img: Tensor) -> Tuple[Tensor, Dict[str, Tensor]]:\n        pass\n\n    @abstractmethod\n    def loss_function(self, img: Tensor, recons_img: Tensor,\n                      **kwargs) -> Tensor:\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:25:46.066673Z","iopub.execute_input":"2024-12-18T04:25:46.067067Z","iopub.status.idle":"2024-12-18T04:25:46.074947Z","shell.execute_reply.started":"2024-12-18T04:25:46.067031Z","shell.execute_reply":"2024-12-18T04:25:46.073869Z"}},"outputs":[],"execution_count":90},{"id":"570cb1cd-9b14-4d75-98dc-a72a01616bcb","cell_type":"code","source":"class ConditionalVAE(BaseVAE):\n    def __init__(self,\n                 in_channels: int,\n                 num_classes: int,\n                 latent_dim: int,\n                 hidden_dims: List = None,\n                 img_size:int = 64,\n                 ) -> None:\n        super(ConditionalVAE, self).__init__()\n        \n        self.latent_dim = latent_dim\n        self.img_size = img_size\n\n        self.embed_class = nn.Linear(num_classes, img_size * img_size)\n        self.embed_data = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n\n        modules = []\n        if hidden_dims is None:\n            hidden_dims = [32, 64, 128, 256, 512]\n\n        in_channels += 1 # To account for the extra label channel\n        # Build Encoder\n        for h_dim in hidden_dims:\n            modules.append(\n                nn.Sequential(\n                    nn.Conv2d(in_channels, out_channels=h_dim,\n                              kernel_size= 3, stride= 2, padding  = 1),\n                    nn.BatchNorm2d(h_dim),\n                    nn.LeakyReLU())\n            )\n            in_channels = h_dim\n\n        self.encoder = nn.Sequential(*modules) \n        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n\n\n        # Build Decoder\n        modules = []\n\n        self.decoder_input = nn.Linear(latent_dim + num_classes, hidden_dims[-1] * 4)\n\n        hidden_dims.reverse()\n\n        for i in range(len(hidden_dims) - 1):\n            modules.append(\n                nn.Sequential(\n                    nn.ConvTranspose2d(hidden_dims[i],\n                                       hidden_dims[i + 1],\n                                       kernel_size=3,\n                                       stride = 2,\n                                       padding=1,\n                                       output_padding=1\n                                       ),\n                    nn.BatchNorm2d(hidden_dims[i + 1]),\n                    nn.LeakyReLU())\n            )\n\n\n\n        self.decoder = nn.Sequential(*modules)\n\n        self.final_layer = nn.Sequential(\n                            nn.ConvTranspose2d(hidden_dims[-1],\n                                               hidden_dims[-1],\n                                               kernel_size=1,\n                                               stride=1,\n                                               padding=2),\n                            nn.BatchNorm2d(hidden_dims[-1]),\n                            nn.LeakyReLU(),\n                            nn.Conv2d(hidden_dims[-1], out_channels= 1,\n                                      kernel_size= 3, padding= 1),\n                            nn.Tanh())\n\n    def encode(self, input: Tensor) -> List[Tensor]:\n\n        result = self.encoder(input)\n        result = torch.flatten(result, start_dim=1)\n\n\n        mu = self.fc_mu(result)\n        log_var = self.fc_var(result)\n\n        return [mu, log_var]\n\n    def decode(self, z: Tensor) -> Tensor:\n        result = self.decoder_input(z)\n        result = result.view(-1, 512, 2, 2)\n        result = self.decoder(result)\n        result = self.final_layer(result)\n        return result\n\n    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return eps * std + mu\n\n    def forward(self, input, y) -> List[Tensor]:\n        y = y.float()\n        embedded_class = self.embed_class(y)\n        embedded_class = embedded_class.view(-1, self.img_size, self.img_size).unsqueeze(1)\n        embedded_input = self.embed_data(input)\n\n        x = torch.cat([embedded_input, embedded_class], dim = 1)\n        mu, log_var = self.encode(x)\n\n        z = self.reparameterize(mu, log_var)\n\n        z = torch.cat([z, y], dim = 1)\n\n        return  self.decode(z), input, mu, log_var\n\n    def loss_function(self,\n                     recons,\n                     input,\n                     mu, log_var) -> dict:\n\n        kld_weight = 0.0025  # Account for the minibatch samples from the dataset\n        recons_loss =F.mse_loss(recons, input)\n\n        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n\n        loss = recons_loss + kld_weight * kld_loss\n        return loss, recons_loss, kld_loss\n\n    def sample(self,\n               num_samples:int,\n               current_device: int,\n               **kwargs) -> Tensor:\n \n        y = kwargs['labels'].float()\n        z = torch.randn(num_samples,\n                        self.latent_dim)\n\n        z = z.to(current_device)\n\n        z = torch.cat([z, y], dim=1)\n        samples = self.decode(z)\n        return samples\n\n    def generate(self, x: Tensor, **kwargs) -> Tensor:\n        \"\"\"\n        Given an input image x, returns the reconstructed image\n        :param x: (Tensor) [B x C x H x W]\n        :return: (Tensor) [B x C x H x W]\n        \"\"\"\n\n        return self.forward(x, **kwargs)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:25:47.330227Z","iopub.execute_input":"2024-12-18T04:25:47.330854Z","iopub.status.idle":"2024-12-18T04:25:47.346901Z","shell.execute_reply.started":"2024-12-18T04:25:47.330820Z","shell.execute_reply":"2024-12-18T04:25:47.345993Z"}},"outputs":[],"execution_count":91},{"id":"0ab8c620-ed1a-49b9-a61e-492c84b94045","cell_type":"code","source":"from torchvision.utils import make_grid\n\nclass cVAEModule(pl.LightningModule):\n    def __init__(self, kl_weight:int=0.0025, rc_weight:int=1, ce_weight: int=10.0):\n        super().__init__()\n        self.net = ConditionalVAE(in_channels=1,img_size= 28, num_classes=10, latent_dim=32)\n        \n        self.kl_weight = kl_weight\n        self.rc_weight = rc_weight\n        self.ce_weight = ce_weight\n\n        self.train_loss = MeanMetric()\n        self.val_loss = MeanMetric()\n        self.test_loss = MeanMetric()\n        \n        self.val_psnr = PeakSignalNoiseRatio()\n        self.val_ssim = StructuralSimilarityIndexMeasure()\n        self.train_psnr = PeakSignalNoiseRatio()\n        self.train_ssim = StructuralSimilarityIndexMeasure()\n\n        self.criterion = nn.CrossEntropyLoss() # for classifier\n        self.classifier = FashionClassifier().to(self.device)\n        self.load_classifier(\"/kaggle/input/classifier/pytorch/fashion_classifier/1/fashion_classifier.ckpt\")\n\n    def forward(self, batch):\n        x, y = batch\n        y_one_hot = F.one_hot(y, num_classes=10)\n        recons, input, mu, log_var = self.net(x, y_one_hot)\n        loss, rc_loss, kl_loss = self.net.loss_function(recons, input, mu, log_var)\n        return recons, loss, rc_loss, kl_loss\n\n    def load_classifier(self, ckpt_path):\n        checkpoint = torch.load(ckpt_path)\n        checkpoint_state_dict = checkpoint['state_dict']\n        checkpoint_state_dict = {k.replace('net.', ''): v for k, v in checkpoint_state_dict.items()}\n        \n        self.classifier.load_state_dict(checkpoint_state_dict)\n        self.classifier.eval()\n        self.classifier = self.classifier.to(self.device)\n        \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        recons, loss, recons_loss, kl_loss = self.forward(batch)\n\n        preds = self.classifier(recons)\n        ce_loss = F.cross_entropy(preds, y)\n        \n        total_loss = loss + self.ce_weight*ce_loss\n        self.train_loss(total_loss)\n        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n\n        if batch_idx%10 == 0:\n            psnr_value = self.train_psnr(recons, x)\n            ssim_value = self.train_ssim(recons, x)\n            \n            reconstruction = make_grid(recons, nrow=10, normalize=True)\n            x = make_grid(x, nrow=10, normalize=True)\n            preds_labels = preds.argmax(dim=1)\n            preds_grid = make_grid(preds_labels.unsqueeze(1).float(), nrow=10, normalize=True)\n            \n            self.logger.log_image(key='train/image', images=[reconstruction, x_grid, preds_grid], caption=['reconstruction', 'real', 'prediction'])   \n            self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"train/psnr\", psnr_value, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"train/ssim\", ssim_value, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n    \n\n    def on_train_epoch_end(self):\n        \"Lightning hook that is called when a validation epoch ends.\"\n        self.train_psnr.reset()\n        self.train_ssim.reset()\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        recons, loss, recons_loss, kl_loss = self.forward(batch)\n        \n        preds = self.classifier(recons)\n        ce_loss = F.cross_entropy(preds, y)\n\n        total_loss = loss + self.ce_weight*ce_loss\n        self.val_loss(total_loss)\n        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n\n        if batch_idx%10 == 0:\n            psnr_value = self.val_psnr(recons, x)\n            ssim_value = self.val_ssim(recons, x)\n            \n            reconstruction = make_grid(recons, nrow=10, normalize=True)\n            x = make_grid(x, nrow=10, normalize=True)\n            \n            preds_labels = preds.argmax(dim=1)\n            preds_grid = make_grid(preds_labels.unsqueeze(1).float(), nrow=10, normalize=True)\n            \n            self.logger.log_image(key='val/image', images=[reconstruction, x_grid, preds_grid], caption=['reconstruction', 'real', 'prediction']) \n            self.log(\"val/psnr\", psnr_value, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"val/ssim\", ssim_value, on_step=False, on_epoch=True, prog_bar=True)\n\n    def on_validation_epoch_end(self):\n        \"Lightning hook that is called when a validation epoch ends.\"\n        self.val_psnr.reset()\n        self.val_ssim.reset()\n\n        \n    def test_step(self,  batch, batch_idx):\n        x, y = batch\n        recons, loss, recons_loss, kl_loss = self.forward(batch)\n\n        self.classifier = self.load_classifier(\"/kaggle/input/classifier/pytorch/fashion_classifier/1/fashion_classifier.ckpt\")\n        preds = self.classifier(recons)\n        ce_loss = F.cross_entropy(preds, y)\n        \n        total_loss = loss + self.ce_weight*ce_loss\n        self.test_loss(total_loss)\n        self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n\n        if batch_idx%10 == 0:\n            \n            reconstruction = make_grid(recons, nrow=10, normalize=True)\n            x = make_grid(x, nrow=10, normalize=True)\n            \n            preds_labels = preds.argmax(dim=1)\n            preds_grid = make_grid(preds_labels.unsqueeze(1).float(), nrow=10, normalize=True)\n            \n            self.logger.log_image(key='test/image', images=[reconstruction, x_grid, preds_grid], caption=['reconstruction', 'real', 'prediction']) \n\n    def configure_optimizers(self):\n        optimizer=torch.optim.Adam(params=self.parameters(), lr=1e-4, weight_decay=1e-5)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=10)\n      \n        return {\n           \"optimizer\": optimizer,\n           \"lr_scheduler\": {\n               \"scheduler\": scheduler,\n               \"monitor\": \"val/loss\",\n           },\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:39:08.307592Z","iopub.execute_input":"2024-12-18T05:39:08.307952Z","iopub.status.idle":"2024-12-18T05:39:08.330250Z","shell.execute_reply.started":"2024-12-18T05:39:08.307920Z","shell.execute_reply":"2024-12-18T05:39:08.329385Z"}},"outputs":[],"execution_count":116},{"id":"7ffd249e-7bf6-4545-9d1b-215d3e9dd845","cell_type":"code","source":"callback = ModelCheckpoint(\n   dirpath=\"checkpoints\",\n   monitor=\"train/psnr\",\n   filename=\"cVAE-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\",\n   save_top_k=3,\n   mode=\"max\",\n)\n\nearly_stopping = EarlyStopping(monitor=\"train/ssim\", patience=15, mode=\"max\", verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:31:59.797338Z","iopub.execute_input":"2024-12-18T04:31:59.798021Z","iopub.status.idle":"2024-12-18T04:31:59.803570Z","shell.execute_reply.started":"2024-12-18T04:31:59.797990Z","shell.execute_reply":"2024-12-18T04:31:59.802638Z"}},"outputs":[],"execution_count":109},{"id":"2bccde1f-50fc-4534-87c5-de79024a3b90","cell_type":"code","source":"# Get the current date and time\ncurrent_datetime = datetime.now(timezone(\"UTC\")).strftime(\"%Y-%m-%d_%H-%M-%S\")\nlogger = WandbLogger(project=\"puvae\", name=f\"run-{current_datetime}\", tags= [\"fashion\", \"cvae\"])\n\nmodel = cVAEModule()\n\ntrainer = pl.Trainer(\n    max_epochs=200,\n    logger=logger,\n    callbacks = [callback, early_stopping],\n    accumulate_grad_batches=2,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    devices=\"auto\",\n)\n\ntrainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)\n\nlogger.experiment.save(\"checkpoints/*.ckpt\")\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T04:32:00.407362Z","iopub.execute_input":"2024-12-18T04:32:00.407699Z","iopub.status.idle":"2024-12-18T05:28:32.284403Z","shell.execute_reply.started":"2024-12-18T04:32:00.407669Z","shell.execute_reply":"2024-12-18T05:28:32.283569Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/496780769.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(ckpt_path)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c22b90413c4981994591982fe5862c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 15 files into the W&B run directory, call wandb.save again to sync new files.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='1430.009 MB of 1693.880 MB uploaded\\r'), FloatProgress(value=0.8442210430644569, m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/psnr</td><td>▁▃▅▅▅▆▇▇▇███████████████████████████████</td></tr><tr><td>train/ssim</td><td>▁▂▂▃▃▅▅▅▅▅▅▅▅▅▆▇████████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>val/loss</td><td>█▇▃▄▃▂▃▂▃▂▂▂▂▁▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▁▁▁▂▂▁▁▂▂▂▂</td></tr><tr><td>val/psnr</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇██▇█▇█▇█▇█▇█▇▇██▇████████</td></tr><tr><td>val/ssim</td><td>▁▃▄▅▅▆▆▆▆▅▇▇█████▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>137</td></tr><tr><td>train/loss</td><td>0.05922</td></tr><tr><td>train/psnr</td><td>16.18061</td></tr><tr><td>train/ssim</td><td>0.7547</td></tr><tr><td>trainer/global_step</td><td>64721</td></tr><tr><td>val/loss</td><td>0.0556</td></tr><tr><td>val/psnr</td><td>16.16596</td></tr><tr><td>val/ssim</td><td>0.75699</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">run-2024-12-18_04-25-50</strong> at: <a href='https://wandb.ai/iai-uet-vnu/puvae/runs/qcgox5g7' target=\"_blank\">https://wandb.ai/iai-uet-vnu/puvae/runs/qcgox5g7</a><br/> View project at: <a href='https://wandb.ai/iai-uet-vnu/puvae' target=\"_blank\">https://wandb.ai/iai-uet-vnu/puvae</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 30377 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241218_042550-qcgox5g7/logs</code>"},"metadata":{}}],"execution_count":110},{"id":"a92a6c0d-8a5d-4268-8bc5-cb3cf93ae07b","cell_type":"markdown","source":"# Adding adversarial attacks","metadata":{}},{"id":"5790a419-49ef-4295-9e9a-9c90b5503100","cell_type":"code","source":"%pip install torchattacks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:33:09.501654Z","iopub.execute_input":"2024-12-18T05:33:09.502024Z","iopub.status.idle":"2024-12-18T05:33:18.243276Z","shell.execute_reply.started":"2024-12-18T05:33:09.501995Z","shell.execute_reply":"2024-12-18T05:33:18.242066Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchattacks in /opt/conda/lib/python3.10/site-packages (3.5.1)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.4.0)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (0.19.0)\nRequirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.14.1)\nRequirement already satisfied: tqdm>=4.56.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (4.66.4)\nRequirement already satisfied: requests~=2.25.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.25.1)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.26.4)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2024.6.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (2024.6.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->torchattacks) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":112},{"id":"6286173c-60da-4cb7-bbbf-a0b135853324","cell_type":"code","source":"def best_reconstruction(model, logger, x, y, n_classes):\n    \"\"\"Identify best reconstruction from PuVAE.\"\"\"\n    batch_size = x.shape[0]\n \n    images = x.repeat_interleave(n_classes, dim=0)\n    labels = torch.eye(n_classes, device=x.device).repeat(batch_size, 1)\n\n    reconstructions, vae_loss = model(images, labels)\n    errors = F.mse_loss(reconstructions, images, reduction='none').mean(dim=[2, 3])\n    errors = errors.view(batch_size, n_classes)\n\n    best_idxs = errors.argmin(dim=1) + torch.arange(0, batch_size, dtype=torch.int64, device=errors.device) * n_classes \n    best_reconstructions = reconstructions[best_idxs]\n\n    return best_reconstructions, errors.min(dim=1).values\n\n\ndef run_attack(model, logger, datamodule, attack):\n    \"\"\"Run adversarial attack and evaluate model performance.\"\"\"\n    correct, total = 0, 0\n    n_classes = datamodule.num_classes\n\n    for batch_idx, batch in enumerate(datamodule.test_dataloader()):\n        x, y = batch\n        x.requires_grad = True\n        labels = torch.argmax(y, dim=1)\n        \n        adv_examples = attack(inputs=x, labels=labels)\n        \n        with torch.no_grad():\n            reconstruction, _ = model(adv_examples, y)\n            best_reconstructions, errors = best_reconstruction(model, logger, adv_examples, y, n_classes)\n            preds = model.classifier(best_reconstructions)\n            preds = torch.argmax(preds, dim=1)\n            \n            # Calculate accuracy\n            correct += (preds == labels).sum().item()\n            total += y.size(0)\n            \n            for i in range(min(len(adv_examples), 5)):  # Log up to 5 examples per batch\n                adv_image = adv_examples[i].detach().cpu()\n                recon_image = reconstruction[i].detach().cpu()\n                original_image = x[i].detach().cpu()\n                captions = [f\"Label: {labels[i].item()}\", f\"Prediction: {preds[i].item()}\", \"Reconstruction\"]\n                \n                logger[0].log_image(key=f\"infer/batch_{batch_idx}_adv_example_{i}\",\n                                 images=[original_image, adv_image, recon_image],\n                                 caption=captions)\n                \n\n    accuracy = 100 * correct / total\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:39:17.943037Z","iopub.execute_input":"2024-12-18T05:39:17.944007Z","iopub.status.idle":"2024-12-18T05:39:17.958954Z","shell.execute_reply.started":"2024-12-18T05:39:17.943951Z","shell.execute_reply":"2024-12-18T05:39:17.957935Z"}},"outputs":[],"execution_count":117},{"id":"5d4af7bc-56a2-47e8-8148-e3b0a7138214","cell_type":"code","source":"trainer.test(model=model, dataloaders = test_loader, ckpt_path = '/kaggle/input/puvae/pytorch/default/1/mnist_cvae.ckpt')\n\nattack = FGSM(model.classifier, eps=cfg.test.attack_eps)\n\naccuracy = run_attack(model, logger, datamodule, attack)\n\nlogger.log_metrics({\"infer/acc\": accuracy})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T05:39:18.470605Z","iopub.execute_input":"2024-12-18T05:39:18.470960Z","iopub.status.idle":"2024-12-18T05:39:18.657404Z","shell.execute_reply.started":"2024-12-18T05:39:18.470927Z","shell.execute_reply":"2024-12-18T05:39:18.656157Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/puvae/pytorch/default/1/mnist_cvae.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m attack \u001b[38;5;241m=\u001b[39m FGSM(model\u001b[38;5;241m.\u001b[39mclassifier, eps\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mattack_eps)\n\u001b[1;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m run_attack(model, logger, datamodule, attack)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:748\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:788\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    785\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    787\u001b[0m )\n\u001b[0;32m--> 788\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    790\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:950\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m    949\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_modules_and_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_results()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:398\u001b[0m, in \u001b[0;36m_CheckpointConnector._restore_modules_and_callbacks\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_restore_modules_and_callbacks\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# restore modules after setup\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_start(checkpoint_path)\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_datamodule()\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;66;03m# restore callback states\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:275\u001b[0m, in \u001b[0;36m_CheckpointConnector.restore_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_load_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_checkpoint)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# restore model state_dict\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loaded_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict_loading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:371\u001b[0m, in \u001b[0;36mStrategy.load_model_state_dict\u001b[0;34m(self, checkpoint, strict)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint: Mapping[\u001b[38;5;28mstr\u001b[39m, Any], strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for cVAEModule:\n\tMissing key(s) in state_dict: \"classifier.conv1.weight\", \"classifier.conv1.bias\", \"classifier.conv2.weight\", \"classifier.conv2.bias\", \"classifier.fc1.weight\", \"classifier.fc1.bias\", \"classifier.fc2.weight\", \"classifier.fc2.bias\". "],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for cVAEModule:\n\tMissing key(s) in state_dict: \"classifier.conv1.weight\", \"classifier.conv1.bias\", \"classifier.conv2.weight\", \"classifier.conv2.bias\", \"classifier.fc1.weight\", \"classifier.fc1.bias\", \"classifier.fc2.weight\", \"classifier.fc2.bias\". ","output_type":"error"}],"execution_count":118},{"id":"85cca637-0ffb-42ce-99d8-8ac9e4ab4284","cell_type":"markdown","source":"# Original VAE","metadata":{}},{"id":"48082911-bcbd-4e37-aba9-c58b490cc1e6","cell_type":"code","source":"class Sampling(nn.Module):\n    def forward(self, z_mean, z_log_var, training):\n        sigma_epsilon = 1.0 if training else 0.1\n        epsilon = torch.randn_like(z_mean) * sigma_epsilon\n        return z_mean + torch.exp(0.5 * torch.clamp(z_log_var, min=-10, max=10)) * epsilon\n    \nclass Encoder(nn.Module):\n    def __init__(self, latent_dim=32, image_size:int=28, channels:int=1, kernel_size:int=7, training:bool=True):\n        super(Encoder, self).__init__()\n        self.latent_dim = latent_dim\n        self.channels = channels\n        self.kernel_size = kernel_size\n        self.image_size = image_size\n        self.training = training\n\n        \n        self.conv1 = nn.Conv2d(self.channels, 32, kernel_size=self.kernel_size, padding='same', dilation=2)\n\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=self.kernel_size, dilation=2, padding='same')\n        self.conv3 = nn.Conv2d(32, 32, kernel_size=self.kernel_size, dilation=2, padding='same')\n        self.conv4 = nn.Conv2d(32, 32, kernel_size=self.kernel_size, dilation=2, padding='same')\n        \n        self.flatten = nn.Flatten()\n        self.dense1 = nn.Linear(self.latent_dim * self.image_size * self.image_size + 10, 1024)\n        self.dense2 = nn.Linear(1024, 1024)\n\n        self.dense3 = nn.Linear(1024, self.latent_dim)\n        self.dense4 = nn.Linear(1024, self.latent_dim)\n        self.softplus = nn.Softplus()\n        self.sampling = Sampling()\n\n    def forward(self, x, y):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n\n        \n        x = F.relu(self.conv4(x))\n            \n        x = self.flatten(x)\n        y_one_hot = F.one_hot(y, num_classes=len(labels))\n        x = torch.cat([x, y_one_hot], dim=-1)\n        \n        x = F.relu(self.dense1(x))\n        x = F.relu(self.dense2(x))\n\n        z_mean = self.dense3(x)\n        z_log_var = self.softplus(self.dense4(x))\n        z = self.sampling(z_mean, z_log_var, self.training)\n        return z_mean, z_log_var, z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:08:50.561804Z","iopub.execute_input":"2024-12-17T15:08:50.562440Z","iopub.status.idle":"2024-12-17T15:08:50.574231Z","shell.execute_reply.started":"2024-12-17T15:08:50.562405Z","shell.execute_reply":"2024-12-17T15:08:50.573396Z"}},"outputs":[],"execution_count":205},{"id":"72e4c23e-65da-432f-8736-78410fd84efe","cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, \n                 latent_dim: int=32, \n                 channels: int=1, \n                 image_size:int=28, \n                 kernel_size:int=7, \n                 hidden_unit:int=512):\n        super(Decoder, self).__init__()\n        self.latent_dim = latent_dim\n        self.channels = channels\n        self.image_size = image_size\n        self.kernel_size = kernel_size\n        self.hidden_unit = hidden_unit\n        \n        self.fc = nn.Linear(32 + 10, self.hidden_unit)  # Adjust based on latent_dim\n        self.deconv1 = nn.ConvTranspose2d(self.hidden_unit, 32, kernel_size=kernel_size, stride=2, padding=0)\n        self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1, dilation=1)\n        self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1)\n        self.deconv4 = nn.ConvTranspose2d(32, 1, kernel_size=3, padding=1)\n\n    def forward(self, x, y):\n        \n        y_one_hot = F.one_hot(y, num_classes=10)\n        x1 = torch.cat((x, y_one_hot), dim=1)\n        x2 = F.relu(self.fc(x1))\n\n        x3 = x2.view(-1, self.hidden_unit, 1, 1)\n        \n        x4 = F.relu(self.deconv1(x3))\n        x5 = F.relu(self.deconv2(x4))\n        x6 = F.relu(self.deconv3(x5))\n        x7 = self.deconv4(x6)      \n        return torch.sigmoid(x7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:08:51.177746Z","iopub.execute_input":"2024-12-17T15:08:51.178087Z","iopub.status.idle":"2024-12-17T15:08:51.186674Z","shell.execute_reply.started":"2024-12-17T15:08:51.178056Z","shell.execute_reply":"2024-12-17T15:08:51.186070Z"}},"outputs":[],"execution_count":206},{"id":"6c74a673-088e-4e4a-a751-4ef49eb0d270","cell_type":"code","source":"class PuVAE(nn.Module):\n    def __init__(self, kl_weight:int=0.1, rc_weight:int=0.01):\n        super(PuVAE, self).__init__()\n        self.kl_weight = kl_weight\n        self.rc_weight = rc_weight\n        self.encoder = Encoder()\n        self.decoder = Decoder()\n        \n    def forward(self, x, y):\n        z_mean, z_log_var, z= self.encoder(x, y)\n        recons = self.decoder(z, y)\n        kl_loss = torch.mean(z_mean**2 + torch.exp(z_log_var) - 1 - z_log_var)\n        return recons, kl_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:08:51.895032Z","iopub.execute_input":"2024-12-17T15:08:51.895386Z","iopub.status.idle":"2024-12-17T15:08:51.902267Z","shell.execute_reply.started":"2024-12-17T15:08:51.895356Z","shell.execute_reply":"2024-12-17T15:08:51.901583Z"}},"outputs":[],"execution_count":207},{"id":"ce0101af-69f2-4af0-aa20-12051b8eaba3","cell_type":"code","source":"from torchvision.utils import make_grid\n\nclass PuVAEModule(pl.LightningModule):\n    def __init__(self, kl_weight:int=0.0025, rc_weight:int=0.1, ce_weight: int=10.0):\n        super().__init__()\n        self.net = PuVAE()\n        self.criterion = nn.CrossEntropyLoss() # for classifier\n        self.kl_weight = kl_weight\n        self.rc_weight = rc_weight\n        self.ce_weight = ce_weight\n\n        self.train_loss = MeanMetric()\n        self.val_loss = MeanMetric()\n        self.test_loss = MeanMetric()\n        \n        self.val_psnr = PeakSignalNoiseRatio()\n        self.val_ssim = StructuralSimilarityIndexMeasure()\n        self.train_psnr = PeakSignalNoiseRatio()\n        self.train_ssim = StructuralSimilarityIndexMeasure()\n\n        # self.classifier = FashionClassifier()\n        # self.load_classifier(\"/kaggle/input/fashionclassifier/pytorch/default/3/classifier.ckpt\")\n\n    def forward(self, batch):\n        x, y = batch\n        return self.net(x, y)\n\n    def load_classifier(self, ckpt_path):\n        checkpoint = torch.load(ckpt_path, map_location=self.device)\n        checkpoint_state_dict = checkpoint['state_dict']\n        checkpoint_state_dict = {k.replace('net.', ''): v for k, v in checkpoint_state_dict.items()}\n        \n        # Load the state dict into the model\n        self.classifier.load_state_dict(checkpoint_state_dict)\n        self.classifier.to(self.device)\n        self.classifier.eval()\n        \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        recons, kl_loss = self.forward(batch)\n        epsilon = 1e-8\n        rc_loss = F.mse_loss(recons, x)\n        \n        \n        # preds = classifier(recons)\n        # ce_loss = F.cross_entropy(preds, y)\n        loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss\n        # total_loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss + self.ce_weight*ce_loss\n        self.train_loss(loss)\n        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n\n        if batch_idx%10 == 0:\n            psnr_value = self.train_psnr(recons, x)\n            ssim_value = self.train_ssim(recons, x)\n            \n            reconstruction = make_grid(recons, nrow=10, normalize=True)\n            x = make_grid(x, nrow=10, normalize=True)\n            self.logger.log_image(key='train/image', images=[reconstruction, x], caption=['reconstruction','real'])        \n            self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"train/psnr\", psnr_value, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"train/ssim\", ssim_value, on_step=False, on_epoch=True, prog_bar=True)\n\n        return loss\n    \n\n    def on_train_epoch_end(self):\n        \"Lightning hook that is called when a validation epoch ends.\"\n        self.train_psnr.reset()\n        self.train_ssim.reset()\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        recons, kl_loss = self.forward(batch)\n        rc_loss = F.mse_loss(recons, x)\n        \n        \n        # preds = classifier(recons)\n        # ce_loss = F.cross_entropy(preds, y)\n\n        loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss\n        # total_loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss + self.ce_weight*ce_loss\n        self.val_loss(loss)\n        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n\n        if batch_idx%10 == 0:\n            psnr_value = self.val_psnr(recons, x)\n            ssim_value = self.val_ssim(recons, x)\n            \n            reconstruction = make_grid(recons, nrow=10, normalize=True)\n            x = make_grid(x, nrow=10, normalize=True)\n            self.logger.log_image(key='val/image', images=[reconstruction, x], caption=['reconstruction','real'])        \n            self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"val/psnr\", psnr_value, on_step=False, on_epoch=True, prog_bar=True)\n            self.log(\"val/ssim\", ssim_value, on_step=False, on_epoch=True, prog_bar=True)\n\n    def on_validation_epoch_end(self):\n        \"Lightning hook that is called when a validation epoch ends.\"\n        self.val_psnr.reset()\n        self.val_ssim.reset()\n\n    def test_step(self,  batch, batch_idx):\n        x, y = batch\n        recons, kl_loss = self.forward(batch)\n        rc_loss = F.mse_loss(recons, x)\n        \n        \n        # preds = classifier(recons)\n        # ce_loss = F.cross_entropy(preds, y)\n        loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss\n        # total_loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss + self.ce_weight*ce_loss\n        self.test_loss(loss)\n        self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer=torch.optim.Adam(params=self.parameters(), lr=1e-4, weight_decay=1e-5)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=10)\n      \n        return {\n           \"optimizer\": optimizer,\n           \"lr_scheduler\": {\n               \"scheduler\": scheduler,\n               \"monitor\": \"val/loss\",\n           },\n        }\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:47:22.615236Z","iopub.execute_input":"2024-12-17T15:47:22.615641Z","iopub.status.idle":"2024-12-17T15:47:22.633541Z","shell.execute_reply.started":"2024-12-17T15:47:22.615601Z","shell.execute_reply":"2024-12-17T15:47:22.632602Z"}},"outputs":[],"execution_count":219},{"id":"c46036ac-0826-4ae3-8c35-0ec8eded9c60","cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n   dirpath=\"checkpoints\",\n   monitor=\"train/psnr\",\n   filename=\"puVAE-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\",\n   save_top_k=3,\n   mode=\"min\",\n)","metadata":{"id":"TpG36XjrmoGY","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:47:23.221689Z","iopub.execute_input":"2024-12-17T15:47:23.222287Z","iopub.status.idle":"2024-12-17T15:47:23.227828Z","shell.execute_reply.started":"2024-12-17T15:47:23.222240Z","shell.execute_reply":"2024-12-17T15:47:23.226906Z"}},"outputs":[],"execution_count":220},{"id":"852a4eb1-ed62-4a8a-a708-350041589fdc","cell_type":"code","source":"# Get the current date and time\ncurrent_datetime = datetime.now(timezone(\"UTC\")).strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n# Initialize the WandbLogger\nlogger = WandbLogger(project=\"puvae\", name=f\"run-{current_datetime}\", tags= [\"fashion\", \"puvae\"])","metadata":{"id":"47Dr-eXPHiaC","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:47:23.827127Z","iopub.execute_input":"2024-12-17T15:47:23.827987Z","iopub.status.idle":"2024-12-17T15:47:23.833181Z","shell.execute_reply.started":"2024-12-17T15:47:23.827948Z","shell.execute_reply":"2024-12-17T15:47:23.832185Z"}},"outputs":[],"execution_count":221},{"id":"391e9cca-99cb-4b7a-bd80-526949cfe779","cell_type":"code","source":"early_stopping = EarlyStopping(monitor=\"train/psnr\", patience=10, mode=\"min\", verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:47:24.405486Z","iopub.execute_input":"2024-12-17T15:47:24.406309Z","iopub.status.idle":"2024-12-17T15:47:24.411176Z","shell.execute_reply.started":"2024-12-17T15:47:24.406254Z","shell.execute_reply":"2024-12-17T15:47:24.410334Z"}},"outputs":[],"execution_count":222},{"id":"4ef2e13a-1e59-4059-b62c-35d6e189e657","cell_type":"code","source":"classifier = classifier.to(DEVICE)\nmodel = PuVAEModule().to(DEVICE)\ntrainer = pl.Trainer(\n    max_epochs=200,\n    logger=logger,\n    callbacks = [checkpoint_callback, early_stopping],\n    accumulate_grad_batches=2,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    devices=\"auto\",\n)\n\ntrainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)\n\nlogger.experiment.save(\"checkpoints/*.ckpt\")\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T15:47:25.000970Z","iopub.execute_input":"2024-12-17T15:47:25.001794Z","iopub.status.idle":"2024-12-17T16:22:50.053745Z","shell.execute_reply.started":"2024-12-17T15:47:25.001760Z","shell.execute_reply":"2024-12-17T16:22:50.052173Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3def60a0d0674c79b53f2bb40de4606f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:205\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 205\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[219], line 49\u001b[0m, in \u001b[0;36mPuVAEModule.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# total_loss = self.rc_weight*rc_loss + self.kl_weight*kl_loss + self.ce_weight*ce_loss\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss, on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:316\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:385\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:550\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/aggregation.py:563\u001b[0m, in \u001b[0;36mMeanMetric.update\u001b[0;34m(self, value, weight)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight, Tensor):\n\u001b[0;32m--> 563\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_to(weight, value\u001b[38;5;241m.\u001b[39mshape)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[223], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m PuVAEModule()\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      4\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      5\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m logger\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/*.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n","\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"],"ename":"NameError","evalue":"name 'exit' is not defined","output_type":"error"}],"execution_count":223}]}